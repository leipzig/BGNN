{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import dataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import CNN\n",
    "import itertools\n",
    "\n",
    "# hyper param search\n",
    "hyperp = {\n",
    "    \"n_epochs\": 3,\n",
    "    \"batchSize\": 200,\n",
    "    \"numOfTrials\": 3,\n",
    "    \"training_count\": 2,\n",
    "    \"validation_count\": 1,\n",
    "    \"imgH\": 28,\n",
    "    \"imgW\": 28,\n",
    "    \"kernels\": [16, 32],\n",
    "    \"kernelSize\": 5\n",
    "}\n",
    "\n",
    "# defining global variables\n",
    "image_path = \"./Fish_toy/images\"\n",
    "\n",
    "# hyper-parameter search\n",
    "hyperp_grid_params = {\n",
    "    \"dummy\": [0], #  keep this when you only need one model\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuda support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0) # 0\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    print(\"We are using cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images =  117\n",
      "Abudefduf vaigiensis  has  4  images\n",
      "Pardachirus pavoninus  has  5  images\n",
      "Wetmorella albofasciata  has  5  images\n",
      "Zebrasoma scopas  has  5  images\n",
      "Acanthurus achilles  has  5  images\n",
      "Anampses caeruleopunctatus  has  5  images\n",
      "Wetmorella nigropinnata  has  5  images\n",
      "Variola albimarginata  has  4  images\n",
      "Upeneus moluccensis  has  5  images\n",
      "Xiphocheilus typus  has  4  images\n",
      "Acanthurus coeruleus  has  5  images\n",
      "Acanthopagrus pacificus  has  3  images\n",
      "Ablabys taenianotus  has  5  images\n",
      "Acanthurus chirurgus  has  5  images\n",
      "Amphiprion clarkii  has  5  images\n",
      "Xenisthmus polyzonatus  has  5  images\n",
      "Acanthemblemaria spinosa  has  4  images\n",
      "Acanthemblemaria aspera  has  5  images\n",
      "Acanthurus bahianus  has  4  images\n",
      "Anampses geographicus  has  5  images\n",
      "Amphiprion polymnus  has  5  images\n",
      "abudefduf septemfasciatus  has  4  images\n",
      "Lepidozygus tapeinosoma  has  5  images\n",
      "Xanthichthys auromarginatus  has  5  images\n",
      "Zanclus cornutus  has  5  images\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-81b96095c57b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataLoader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLoadersFromDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumberOfSpecies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernelSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mloss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Insync/mndhamod@gmail.com/Google Drive/Colab Notebooks/BGNN/CNN.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, numberOfClasses, imgH, imgW, kernels, kernelSize)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumOfLayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mout_ch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_ch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_ch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernelSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_pool_kernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode)\u001b[0m\n\u001b[1;32m    330\u001b[0m         super(Conv2d, self).__init__(\n\u001b[1;32m    331\u001b[0m             \u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             False, _pair(0), groups, bias, padding_mode)\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             self.weight = Parameter(torch.Tensor(\n\u001b[0;32m---> 41\u001b[0;31m                 out_channels, in_channels // groups, *kernel_size))\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from confusion_matrix_plotter import plot_confusion_matrix2\n",
    "from helper import getModelName\n",
    "import numpy as np\n",
    "\n",
    "# get possible experiments\n",
    "keys, values = zip(*hyperp_grid_params.items())\n",
    "product = itertools.product(*values)\n",
    "product_len = len(list(product))\n",
    "\n",
    "# Just used to print information about data set\n",
    "dummy = 10\n",
    "dataLoader.FishDataset(image_path, dummy, dummy, True)\n",
    "confusionMatrices = []\n",
    "datasets = []\n",
    "\n",
    "for v in itertools.product(*values):\n",
    "    # create experiment params\n",
    "    experiment_params = dict(zip(keys, v))\n",
    "    experiment_params = {**hyperp, **experiment_params}\n",
    "    numOfTrials = experiment_params[\"numOfTrials\"]\n",
    "    imgH = experiment_params[\"imgH\"]\n",
    "    imgW = experiment_params[\"imgW\"]\n",
    "    n_epochs = experiment_params[\"n_epochs\"]\n",
    "    batchSize = experiment_params[\"batchSize\"]\n",
    "    training_count = experiment_params[\"training_count\"]\n",
    "    validation_count = experiment_params[\"validation_count\"]\n",
    "    kernels = experiment_params[\"kernels\"]\n",
    "    kernelSize = experiment_params[\"kernelSize\"]\n",
    "    \n",
    "    # load images\n",
    "    dataset = dataLoader.FishDataset(image_path, imgH, imgW)\n",
    "    datasets.append(dataset)\n",
    "    numberOfSpecies = len(dataset.getSpeciesList())\n",
    "    \n",
    "    confusionMatricesPerExperiment = []\n",
    "    \n",
    "    for i in range(numOfTrials):\n",
    "\n",
    "        # Initialize the prediction and label lists(tensors)\n",
    "        predlist=torch.zeros(0)\n",
    "        lbllist=torch.zeros(0)\n",
    "\n",
    "        # get Loaders\n",
    "        train_loader, validation_loader, test_loader = dataLoader.getLoadersFromDataset(dataset, training_count, validation_count, batchSize)\n",
    "\n",
    "        model = CNN.CNN(numberOfSpecies, imgH, imgW, kernels, kernelSize)\n",
    "        loss_list, accuracy_list = CNN.trainModel(train_loader, validation_loader, n_epochs, model, int(n_epochs/10))\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                inputs = batch[\"image\"]\n",
    "                classes = batch[\"class\"]\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                predlist=torch.cat([predlist,preds.float().view(-1)])\n",
    "                lbllist=torch.cat([lbllist,classes.float().view(-1)])\n",
    "\n",
    "        # Confusion matrix\n",
    "        confusionMatricesPerExperiment.append(confusion_matrix(lbllist.cpu().numpy(), predlist.cpu().numpy(), labels = range(numberOfSpecies)))\n",
    "    \n",
    "    conf_mat = np.mean(confusionMatricesPerExperiment, axis=0) \n",
    "    plot_confusion_matrix2(conf_mat,\n",
    "                              dataset.getSpeciesList(),\n",
    "                              title=getModelName(experiment_params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
