{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import CNN\n",
    "import numpy as np\n",
    "\n",
    "# from config_plots import global_settings\n",
    "# global_settings()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining global variables\n",
    "experimentName = \"test_22987_suffix50_11\"\n",
    "useRandomSearch = False\n",
    "numOfExperiments=100\n",
    "\n",
    "from configParser import ConfigParser, getModelName\n",
    "hyperpSearchObject = ConfigParser(experimentName).getHyperpSearchObject()\n",
    "\n",
    "experimentName = experimentName + \"/hyperp-search\"\n",
    "import TrialStatistics\n",
    "ts = TrialStatistics.TrialStatistics(experimentName)\n",
    "\n",
    "Use_old_dataLoader = False\n",
    "if Use_old_dataLoader:\n",
    "    import dataLoader\n",
    "else:\n",
    "    import dataLoader2 as dataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuda support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0) # 0\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    print(\"We are using cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch import nn\n",
    "\n",
    "all_experiment_params = []\n",
    "def objective(experiment_params):\n",
    "    experiment_params[\"numOfTrials\"] = experiment_params[\"numOfTrials\"] or 1\n",
    "    \n",
    "    print(\"experiment: \", experiment_params)\n",
    "    all_experiment_params.append(experiment_params)\n",
    "    \n",
    "    # load images\n",
    "    dataset = dataLoader.FishDataset(experiment_params)\n",
    "    numberOfSpecies = len(dataset.getSpeciesList())\n",
    "\n",
    "    for i in range(experiment_params[\"numOfTrials\"]):\n",
    "        trialName = experimentName+\"/\"+getModelName(experiment_params, i)\n",
    "\n",
    "        # Train/Load model\n",
    "        model = CNN.CNN(numberOfSpecies, experiment_params)\n",
    "        if os.path.exists(CNN.getModelFile(trialName)):\n",
    "            CNN.loadModel(model, trialName)\n",
    "            test_loader = dataLoader.loadTestLoader(trialName)\n",
    "            print(\"Model {0} loaded!\".format(trialName))\n",
    "        else:\n",
    "            train_loader, validation_loader, test_loader = dataLoader.getLoadersFromDataset(dataset, \n",
    "                                                                                            experiment_params, \n",
    "                                                                                            trialName)\n",
    "            loss_list, accuracy_list, epochs, time_elapsed = CNN.trainModel(train_loader, \n",
    "                                                                            validation_loader, \n",
    "                                                                            experiment_params, \n",
    "                                                                            model, trialName)\n",
    "        \n",
    "        # Update trial outcomes for statistics\n",
    "        predlist, lbllist = CNN.getLoaderPredictions(test_loader, model)\n",
    "        ts.addTrialPredictions(experiment_params, predlist, lbllist, numberOfSpecies)\n",
    "\n",
    "        ts.addTrial(experiment_params,\n",
    "                    {'loss': CNN.getCrossEntropyFromLoader(test_loader, model),\n",
    "                     'accuracy': CNN.getAccuracyFromLoader(test_loader, model),\n",
    "                     'time': time_elapsed,\n",
    "                     'epochs': epochs\n",
    "                    }, i)\n",
    "                \n",
    "    answer ={\n",
    "        'loss': ts.getStatistic(experiment_params, 'loss', 'mean'),\n",
    "        'loss-std': ts.getStatistic(experiment_params, 'loss', 'std'),\n",
    "        'time': ts.getStatistic(experiment_params, 'time', 'mean'),\n",
    "        'time-std': ts.getStatistic(experiment_params, 'time', 'std'),\n",
    "        'epochs': ts.getStatistic(experiment_params, 'epochs', 'mean'),\n",
    "        'epochs-std': ts.getStatistic(experiment_params, 'epochs', 'std'),\n",
    "        'accuracy': ts.getStatistic(experiment_params, 'accuracy', 'mean'),\n",
    "        'accuracy-std': ts.getStatistic(experiment_params, 'accuracy', 'std'),\n",
    "        'status': STATUS_OK,}\n",
    "    \n",
    "    return {**experiment_params, **answer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment:                                            \n",
      "{'batchSize': 200, 'imageDimension': 280, 'image_path': '/data/BGNN_data/INHS_cropped', 'kernelSize': 6, 'kernels': (15, 23, 5, 2, 2), 'n_channels': 1, 'n_epochs': 1000, 'numOfTrials': 1, 'patience': 50, 'suffix': '50_11', 'training_count': 0.64, 'useZCAWhitening': True, 'validation_count': 0.16}\n",
      "Loading dataset...                                     \n",
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (550 of 550) |######################| Elapsed Time: 0:00:04 Time:  0:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved dataset structure...\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, hp, STATUS_OK, Trials, space_eval, plotting, rand, tpe\n",
    "import pickle\n",
    "\n",
    "trials = Trials()\n",
    "bestLoss = fmin(objective, \n",
    "                        space=hyperpSearchObject, \n",
    "                        algo=rand.suggest if useRandomSearch == False else tpe.suggest, \n",
    "                        trials=trials,\n",
    "                        max_evals=numOfExperiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.showStatistics()\n",
    "ts.showStatistics(False)\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# bestParams = space_eval(hyperpSearchObject, bestLoss)\n",
    "# print(\"best params = \", pd.DataFrame(bestParams, index=[0]))\n",
    "best_trial = sorted(trials.results, key=lambda x: x['loss'], reverse=False)[0]\n",
    "best_trial['kernels'] = str(' '.join([str(elem) for elem in best_trial['kernels']]))\n",
    "print(\"Best trial\")\n",
    "display(HTML(pd.DataFrame(best_trial, index=[0]).to_html()))\n",
    "\n",
    "# save trials\n",
    "pickle.dump(trials, open(experimentName+\"/trials.p\", \"wb\"))\n",
    "ts.saveStatistics()\n",
    "ts.saveStatistics(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment_params in all_experiment_params:    \n",
    "    print(\"experiment: \", experiment_params)\n",
    "    \n",
    "    dataset = dataLoader.FishDataset(experiment_params, False)\n",
    "    speciesList = dataset.getSpeciesList()\n",
    "    ts.printTrialConfusionMatrix(experiment_params, speciesList, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
