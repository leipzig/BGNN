{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import CNN\n",
    "\n",
    "# from config_plots import global_settings\n",
    "# global_settings()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining global variables\n",
    "experimentName = \"test_22987_suffix50_11_CNN2_differentConfig_SGD\"\n",
    "showListOfSpecies = False\n",
    "\n",
    "from configParser import ConfigParser, getModelName\n",
    "config_parser = ConfigParser(experimentName)\n",
    "\n",
    "import os\n",
    "experimentName = os.path.join(experimentName, \"selected-multi-trial\")\n",
    "import TrialStatistics\n",
    "ts = TrialStatistics.TrialStatistics(experimentName)\n",
    "ts_genus = TrialStatistics.TrialStatistics(experimentName, \"genus\")\n",
    "\n",
    "import dataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuda support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using cuda\n"
     ]
    }
   ],
   "source": [
    "# CUDA support \n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0) # 0\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    print(\"We are using cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "N/A% (0 of 5) |                          | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment  1 / 5 :  {'image_path': '/data/BGNN_data/INHS_cropped', 'suffix': '50_11', 'training_count': 0.64, 'validation_count': 0.16, 'imageDimension': 224, 'n_channels': 3, 'augmentation': False, 'batchSize': 200, 'n_epochs': 1000, 'learning_rate': 1e-05, 'numOfTrials': 3, 'patience': 100, 'useHeirarchy': True, 'useRelu': False, 'downsample': True, 'downsampleOutput': 50, 'takeFromIntermediate': True, 'takeFromIntermediateOutput': 50, 'useAdam': False, 'normalize': True, 'fc_layers': 1, 'softmax': False, 'resnet': 18}\n",
      "file /data/BGNN_data/INHS_cropped/50_11/test_22987_suffix50_11_CNN2_differentConfig_SGD/selected-multi-trial/tc0.640000_vc0.160000_d224_c3_augFalse_nTrue/dataset.pkl read\n",
      "Loading saved dataloaders...\n",
      "file /data/BGNN_data/INHS_cropped/50_11/test_22987_suffix50_11_CNN2_differentConfig_SGD/selected-multi-trial/tc0.640000_vc0.160000_d224_c3_augFalse_nTrue/trainingLoader.pkl read\n",
      "file /data/BGNN_data/INHS_cropped/50_11/test_22987_suffix50_11_CNN2_differentConfig_SGD/selected-multi-trial/tc0.640000_vc0.160000_d224_c3_augFalse_nTrue/valLoader.pkl read\n",
      "file /data/BGNN_data/INHS_cropped/50_11/test_22987_suffix50_11_CNN2_differentConfig_SGD/selected-multi-trial/tc0.640000_vc0.160000_d224_c3_augFalse_nTrue/testLoader.pkl read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CNN_heirarchy:\n\tMissing key(s) in state_dict: \"module_list.0.layer1.0.conv3.weight\", \"module_list.0.layer1.0.bn3.weight\", \"module_list.0.layer1.0.bn3.bias\", \"module_list.0.layer1.0.bn3.running_mean\", \"module_list.0.layer1.0.bn3.running_var\", \"module_list.0.layer1.0.downsample.0.weight\", \"module_list.0.layer1.0.downsample.1.weight\", \"module_list.0.layer1.0.downsample.1.bias\", \"module_list.0.layer1.0.downsample.1.running_mean\", \"module_list.0.layer1.0.downsample.1.running_var\", \"module_list.0.layer1.1.conv3.weight\", \"module_list.0.layer1.1.bn3.weight\", \"module_list.0.layer1.1.bn3.bias\", \"module_list.0.layer1.1.bn3.running_mean\", \"module_list.0.layer1.1.bn3.running_var\", \"module_list.0.layer1.2.conv1.weight\", \"module_list.0.layer1.2.bn1.weight\", \"module_list.0.layer1.2.bn1.bias\", \"module_list.0.layer1.2.bn1.running_mean\", \"module_list.0.layer1.2.bn1.running_var\", \"module_list.0.layer1.2.conv2.weight\", \"module_list.0.layer1.2.bn2.weight\", \"module_list.0.layer1.2.bn2.bias\", \"module_list.0.layer1.2.bn2.running_mean\", \"module_list.0.layer1.2.bn2.running_var\", \"module_list.0.layer1.2.conv3.weight\", \"module_list.0.layer1.2.bn3.weight\", \"module_list.0.layer1.2.bn3.bias\", \"module_list.0.layer1.2.bn3.running_mean\", \"module_list.0.layer1.2.bn3.running_var\", \"module_list.0.layer2.0.conv3.weight\", \"module_list.0.layer2.0.bn3.weight\", \"module_list.0.layer2.0.bn3.bias\", \"module_list.0.layer2.0.bn3.running_mean\", \"module_list.0.layer2.0.bn3.running_var\", \"module_list.0.layer2.1.conv3.weight\", \"module_list.0.layer2.1.bn3.weight\", \"module_list.0.layer2.1.bn3.bias\", \"module_list.0.layer2.1.bn3.running_mean\", \"module_list.0.layer2.1.bn3.running_var\", \"module_list.0.layer2.2.conv1.weight\", \"module_list.0.layer2.2.bn1.weight\", \"module_list.0.layer2.2.bn1.bias\", \"module_list.0.layer2.2.bn1.running_mean\", \"module_list.0.layer2.2.bn1.running_var\", \"module_list.0.layer2.2.conv2.weight\", \"module_list.0.layer2.2.bn2.weight\", \"module_list.0.layer2.2.bn2.bias\", \"module_list.0.layer2.2.bn2.running_mean\", \"module_list.0.layer2.2.bn2.running_var\", \"module_list.0.layer2.2.conv3.weight\", \"module_list.0.layer2.2.bn3.weight\", \"module_list.0.layer2.2.bn3.bias\", \"module_list.0.layer2.2.bn3.running_mean\", \"module_list.0.layer2.2.bn3.running_var\", \"module_list.0.layer2.3.conv1.weight\", \"module_list.0.layer2.3.bn1.weight\", \"module_list.0.layer2.3.bn1.bias\", \"module_list.0.layer2.3.bn1.running_mean\", \"module_list.0.layer2.3.bn1.running_var\", \"module_list.0.layer2.3.conv2.weight\", \"module_list.0.layer2.3.bn2.weight\", \"module_list.0.layer2.3.bn2.bias\", \"module_list.0.layer2.3.bn2.running_mean\", \"module_list.0.layer2.3.bn2.running_var\", \"module_list.0.layer2.3.conv3.weight\", \"module_list.0.layer2.3.bn3.weight\", \"module_list.0.layer2.3.bn3.bias\", \"module_list.0.layer2.3.bn3.running_mean\", \"module_list.0.layer2.3.bn3.running_var\", \"module_list.0.layer3.0.conv3.weight\", \"module_list.0.layer3.0.bn3.weight\", \"module_list.0.layer3.0.bn3.bias\", \"module_list.0.layer3.0.bn3.running_mean\", \"module_list.0.layer3.0.bn3.running_var\", \"module_list.0.layer3.1.conv3.weight\", \"module_list.0.layer3.1.bn3.weight\", \"module_list.0.layer3.1.bn3.bias\", \"module_list.0.layer3.1.bn3.running_mean\", \"module_list.0.layer3.1.bn3.running_var\", \"module_list.0.layer3.2.conv1.weight\", \"module_list.0.layer3.2.bn1.weight\", \"module_list.0.layer3.2.bn1.bias\", \"module_list.0.layer3.2.bn1.running_mean\", \"module_list.0.layer3.2.bn1.running_var\", \"module_list.0.layer3.2.conv2.weight\", \"module_list.0.layer3.2.bn2.weight\", \"module_list.0.layer3.2.bn2.bias\", \"module_list.0.layer3.2.bn2.running_mean\", \"module_list.0.layer3.2.bn2.running_var\", \"module_list.0.layer3.2.conv3.weight\", \"module_list.0.layer3.2.bn3.weight\", \"module_list.0.layer3.2.bn3.bias\", \"module_list.0.layer3.2.bn3.running_mean\", \"module_list.0.layer3.2.bn3.running_var\", \"module_list.0.layer3.3.conv1.weight\", \"module_list.0.layer3.3.bn1.weight\", \"module_list.0.layer3.3.bn1.bias\", \"module_list.0.layer3.3.bn1.running_mean\", \"module_list.0.layer3.3.bn1.running_var\", \"module_list.0.layer3.3.conv2.weight\", \"module_list.0.layer3.3.bn2.weight\", \"module_list.0.layer3.3.bn2.bias\", \"module_list.0.layer3.3.bn2.running_mean\", \"module_list.0.layer3.3.bn2.running_var\", \"module_list.0.layer3.3.conv3.weight\", \"module_list.0.layer3.3.bn3.weight\", \"module_list.0.layer3.3.bn3.bias\", \"module_list.0.layer3.3.bn3.running_mean\", \"module_list.0.layer3.3.bn3.running_var\", \"module_list.0.layer3.4.conv1.weight\", \"module_list.0.layer3.4.bn1.weight\", \"module_list.0.layer3.4.bn1.bias\", \"module_list.0.layer3.4.bn1.running_mean\", \"module_list.0.layer3.4.bn1.running_var\", \"module_list.0.layer3.4.conv2.weight\", \"module_list.0.layer3.4.bn2.weight\", \"module_list.0.layer3.4.bn2.bias\", \"module_list.0.layer3.4.bn2.running_mean\", \"module_list.0.layer3.4.bn2.running_var\", \"module_list.0.layer3.4.conv3.weight\", \"module_list.0.layer3.4.bn3.weight\", \"module_list.0.layer3.4.bn3.bias\", \"module_list.0.layer3.4.bn3.running_mean\", \"module_list.0.layer3.4.bn3.running_var\", \"module_list.0.layer3.5.conv1.weight\", \"module_list.0.layer3.5.bn1.weight\", \"module_list.0.layer3.5.bn1.bias\", \"module_list.0.layer3.5.bn1.running_mean\", \"module_list.0.layer3.5.bn1.running_var\", \"module_list.0.layer3.5.conv2.weight\", \"module_list.0.layer3.5.bn2.weight\", \"module_list.0.layer3.5.bn2.bias\", \"module_list.0.layer3.5.bn2.running_mean\", \"module_list.0.layer3.5.bn2.running_var\", \"module_list.0.layer3.5.conv3.weight\", \"module_list.0.layer3.5.bn3.weight\", \"module_list.0.layer3.5.bn3.bias\", \"module_list.0.layer3.5.bn3.running_mean\", \"module_list.0.layer3.5.bn3.running_var\", \"module_list.0.layer4.0.conv3.weight\", \"module_list.0.layer4.0.bn3.weight\", \"module_list.0.layer4.0.bn3.bias\", \"module_list.0.layer4.0.bn3.running_mean\", \"module_list.0.layer4.0.bn3.running_var\", \"module_list.0.layer4.1.conv3.weight\", \"module_list.0.layer4.1.bn3.weight\", \"module_list.0.layer4.1.bn3.bias\", \"module_list.0.layer4.1.bn3.running_mean\", \"module_list.0.layer4.1.bn3.running_var\", \"module_list.0.layer4.2.conv1.weight\", \"module_list.0.layer4.2.bn1.weight\", \"module_list.0.layer4.2.bn1.bias\", \"module_list.0.layer4.2.bn1.running_mean\", \"module_list.0.layer4.2.bn1.running_var\", \"module_list.0.layer4.2.conv2.weight\", \"module_list.0.layer4.2.bn2.weight\", \"module_list.0.layer4.2.bn2.bias\", \"module_list.0.layer4.2.bn2.running_mean\", \"module_list.0.layer4.2.bn2.running_var\", \"module_list.0.layer4.2.conv3.weight\", \"module_list.0.layer4.2.bn3.weight\", \"module_list.0.layer4.2.bn3.bias\", \"module_list.0.layer4.2.bn3.running_mean\", \"module_list.0.layer4.2.bn3.running_var\", \"module_list.0.fc.linear0.weight\", \"module_list.0.fc.linear0.bias\", \"module_list.1.4.0.conv3.weight\", \"module_list.1.4.0.bn3.weight\", \"module_list.1.4.0.bn3.bias\", \"module_list.1.4.0.bn3.running_mean\", \"module_list.1.4.0.bn3.running_var\", \"module_list.1.4.0.downsample.0.weight\", \"module_list.1.4.0.downsample.1.weight\", \"module_list.1.4.0.downsample.1.bias\", \"module_list.1.4.0.downsample.1.running_mean\", \"module_list.1.4.0.downsample.1.running_var\", \"module_list.1.4.1.conv3.weight\", \"module_list.1.4.1.bn3.weight\", \"module_list.1.4.1.bn3.bias\", \"module_list.1.4.1.bn3.running_mean\", \"module_list.1.4.1.bn3.running_var\", \"module_list.1.4.2.conv1.weight\", \"module_list.1.4.2.bn1.weight\", \"module_list.1.4.2.bn1.bias\", \"module_list.1.4.2.bn1.running_mean\", \"module_list.1.4.2.bn1.running_var\", \"module_list.1.4.2.conv2.weight\", \"module_list.1.4.2.bn2.weight\", \"module_list.1.4.2.bn2.bias\", \"module_list.1.4.2.bn2.running_mean\", \"module_list.1.4.2.bn2.running_var\", \"module_list.1.4.2.conv3.weight\", \"module_list.1.4.2.bn3.weight\", \"module_list.1.4.2.bn3.bias\", \"module_list.1.4.2.bn3.running_mean\", \"module_list.1.4.2.bn3.running_var\", \"module_list.1.5.0.conv3.weight\", \"module_list.1.5.0.bn3.weight\", \"module_list.1.5.0.bn3.bias\", \"module_list.1.5.0.bn3.running_mean\", \"module_list.1.5.0.bn3.running_var\", \"module_list.1.5.1.conv3.weight\", \"module_list.1.5.1.bn3.weight\", \"module_list.1.5.1.bn3.bias\", \"module_list.1.5.1.bn3.running_mean\", \"module_list.1.5.1.bn3.running_var\", \"module_list.1.5.2.conv1.weight\", \"module_list.1.5.2.bn1.weight\", \"module_list.1.5.2.bn1.bias\", \"module_list.1.5.2.bn1.running_mean\", \"module_list.1.5.2.bn1.running_var\", \"module_list.1.5.2.conv2.weight\", \"module_list.1.5.2.bn2.weight\", \"module_list.1.5.2.bn2.bias\", \"module_list.1.5.2.bn2.running_mean\", \"module_list.1.5.2.bn2.running_var\", \"module_list.1.5.2.conv3.weight\", \"module_list.1.5.2.bn3.weight\", \"module_list.1.5.2.bn3.bias\", \"module_list.1.5.2.bn3.running_mean\", \"module_list.1.5.2.bn3.running_var\", \"module_list.1.5.3.conv1.weight\", \"module_list.1.5.3.bn1.weight\", \"module_list.1.5.3.bn1.bias\", \"module_list.1.5.3.bn1.running_mean\", \"module_list.1.5.3.bn1.running_var\", \"module_list.1.5.3.conv2.weight\", \"module_list.1.5.3.bn2.weight\", \"module_list.1.5.3.bn2.bias\", \"module_list.1.5.3.bn2.running_mean\", \"module_list.1.5.3.bn2.running_var\", \"module_list.1.5.3.conv3.weight\", \"module_list.1.5.3.bn3.weight\", \"module_list.1.5.3.bn3.bias\", \"module_list.1.5.3.bn3.running_mean\", \"module_list.1.5.3.bn3.running_var\", \"module_list.1.6.0.conv3.weight\", \"module_list.1.6.0.bn3.weight\", \"module_list.1.6.0.bn3.bias\", \"module_list.1.6.0.bn3.running_mean\", \"module_list.1.6.0.bn3.running_var\", \"module_list.1.6.1.conv3.weight\", \"module_list.1.6.1.bn3.weight\", \"module_list.1.6.1.bn3.bias\", \"module_list.1.6.1.bn3.running_mean\", \"module_list.1.6.1.bn3.running_var\", \"module_list.1.6.2.conv1.weight\", \"module_list.1.6.2.bn1.weight\", \"module_list.1.6.2.bn1.bias\", \"module_list.1.6.2.bn1.running_mean\", \"module_list.1.6.2.bn1.running_var\", \"module_list.1.6.2.conv2.weight\", \"module_list.1.6.2.bn2.weight\", \"module_list.1.6.2.bn2.bias\", \"module_list.1.6.2.bn2.running_mean\", \"module_list.1.6.2.bn2.running_var\", \"module_list.1.6.2.conv3.weight\", \"module_list.1.6.2.bn3.weight\", \"module_list.1.6.2.bn3.bias\", \"module_list.1.6.2.bn3.running_mean\", \"module_list.1.6.2.bn3.running_var\", \"module_list.1.6.3.conv1.weight\", \"module_list.1.6.3.bn1.weight\", \"module_list.1.6.3.bn1.bias\", \"module_list.1.6.3.bn1.running_mean\", \"module_list.1.6.3.bn1.running_var\", \"module_list.1.6.3.conv2.weight\", \"module_list.1.6.3.bn2.weight\", \"module_list.1.6.3.bn2.bias\", \"module_list.1.6.3.bn2.running_mean\", \"module_list.1.6.3.bn2.running_var\", \"module_list.1.6.3.conv3.weight\", \"module_list.1.6.3.bn3.weight\", \"module_list.1.6.3.bn3.bias\", \"module_list.1.6.3.bn3.running_mean\", \"module_list.1.6.3.bn3.running_var\", \"module_list.1.6.4.conv1.weight\", \"module_list.1.6.4.bn1.weight\", \"module_list.1.6.4.bn1.bias\", \"module_list.1.6.4.bn1.running_mean\", \"module_list.1.6.4.bn1.running_var\", \"module_list.1.6.4.conv2.weight\", \"module_list.1.6.4.bn2.weight\", \"module_list.1.6.4.bn2.bias\", \"module_list.1.6.4.bn2.running_mean\", \"module_list.1.6.4.bn2.running_var\", \"module_list.1.6.4.conv3.weight\", \"module_list.1.6.4.bn3.weight\", \"module_list.1.6.4.bn3.bias\", \"module_list.1.6.4.bn3.running_mean\", \"module_list.1.6.4.bn3.running_var\", \"module_list.1.6.5.conv1.weight\", \"module_list.1.6.5.bn1.weight\", \"module_list.1.6.5.bn1.bias\", \"module_list.1.6.5.bn1.running_mean\", \"module_list.1.6.5.bn1.running_var\", \"module_list.1.6.5.conv2.weight\", \"module_list.1.6.5.bn2.weight\", \"module_list.1.6.5.bn2.bias\", \"module_list.1.6.5.bn2.running_mean\", \"module_list.1.6.5.bn2.running_var\", \"module_list.1.6.5.conv3.weight\", \"module_list.1.6.5.bn3.weight\", \"module_list.1.6.5.bn3.bias\", \"module_list.1.6.5.bn3.running_mean\", \"module_list.1.6.5.bn3.running_var\", \"module_list.1.7.0.conv3.weight\", \"module_list.1.7.0.bn3.weight\", \"module_list.1.7.0.bn3.bias\", \"module_list.1.7.0.bn3.running_mean\", \"module_list.1.7.0.bn3.running_var\", \"module_list.1.7.1.conv3.weight\", \"module_list.1.7.1.bn3.weight\", \"module_list.1.7.1.bn3.bias\", \"module_list.1.7.1.bn3.running_mean\", \"module_list.1.7.1.bn3.running_var\", \"module_list.1.7.2.conv1.weight\", \"module_list.1.7.2.bn1.weight\", \"module_list.1.7.2.bn1.bias\", \"module_list.1.7.2.bn1.running_mean\", \"module_list.1.7.2.bn1.running_var\", \"module_list.1.7.2.conv2.weight\", \"module_list.1.7.2.bn2.weight\", \"module_list.1.7.2.bn2.bias\", \"module_list.1.7.2.bn2.running_mean\", \"module_list.1.7.2.bn2.running_var\", \"module_list.1.7.2.conv3.weight\", \"module_list.1.7.2.bn3.weight\", \"module_list.1.7.2.bn3.bias\", \"module_list.1.7.2.bn3.running_mean\", \"module_list.1.7.2.bn3.running_var\", \"module_list.2.linear0.weight\", \"module_list.2.linear0.bias\", \"module_list.3.linear0.weight\", \"module_list.3.linear0.bias\", \"module_list.4.linear0.weight\", \"module_list.4.linear0.bias\", \"pretrained_model.layer1.0.conv3.weight\", \"pretrained_model.layer1.0.bn3.weight\", \"pretrained_model.layer1.0.bn3.bias\", \"pretrained_model.layer1.0.bn3.running_mean\", \"pretrained_model.layer1.0.bn3.running_var\", \"pretrained_model.layer1.0.downsample.0.weight\", \"pretrained_model.layer1.0.downsample.1.weight\", \"pretrained_model.layer1.0.downsample.1.bias\", \"pretrained_model.layer1.0.downsample.1.running_mean\", \"pretrained_model.layer1.0.downsample.1.running_var\", \"pretrained_model.layer1.1.conv3.weight\", \"pretrained_model.layer1.1.bn3.weight\", \"pretrained_model.layer1.1.bn3.bias\", \"pretrained_model.layer1.1.bn3.running_mean\", \"pretrained_model.layer1.1.bn3.running_var\", \"pretrained_model.layer1.2.conv1.weight\", \"pretrained_model.layer1.2.bn1.weight\", \"pretrained_model.layer1.2.bn1.bias\", \"pretrained_model.layer1.2.bn1.running_mean\", \"pretrained_model.layer1.2.bn1.running_var\", \"pretrained_model.layer1.2.conv2.weight\", \"pretrained_model.layer1.2.bn2.weight\", \"pretrained_model.layer1.2.bn2.bias\", \"pretrained_model.layer1.2.bn2.running_mean\", \"pretrained_model.layer1.2.bn2.running_var\", \"pretrained_model.layer1.2.conv3.weight\", \"pretrained_model.layer1.2.bn3.weight\", \"pretrained_model.layer1.2.bn3.bias\", \"pretrained_model.layer1.2.bn3.running_mean\", \"pretrained_model.layer1.2.bn3.running_var\", \"pretrained_model.layer2.0.conv3.weight\", \"pretrained_model.layer2.0.bn3.weight\", \"pretrained_model.layer2.0.bn3.bias\", \"pretrained_model.layer2.0.bn3.running_mean\", \"pretrained_model.layer2.0.bn3.running_var\", \"pretrained_model.layer2.1.conv3.weight\", \"pretrained_model.layer2.1.bn3.weight\", \"pretrained_model.layer2.1.bn3.bias\", \"pretrained_model.layer2.1.bn3.running_mean\", \"pretrained_model.layer2.1.bn3.running_var\", \"pretrained_model.layer2.2.conv1.weight\", \"pretrained_model.layer2.2.bn1.weight\", \"pretrained_model.layer2.2.bn1.bias\", \"pretrained_model.layer2.2.bn1.running_mean\", \"pretrained_model.layer2.2.bn1.running_var\", \"pretrained_model.layer2.2.conv2.weight\", \"pretrained_model.layer2.2.bn2.weight\", \"pretrained_model.layer2.2.bn2.bias\", \"pretrained_model.layer2.2.bn2.running_mean\", \"pretrained_model.layer2.2.bn2.running_var\", \"pretrained_model.layer2.2.conv3.weight\", \"pretrained_model.layer2.2.bn3.weight\", \"pretrained_model.layer2.2.bn3.bias\", \"pretrained_model.layer2.2.bn3.running_mean\", \"pretrained_model.layer2.2.bn3.running_var\", \"pretrained_model.layer2.3.conv1.weight\", \"pretrained_model.layer2.3.bn1.weight\", \"pretrained_model.layer2.3.bn1.bias\", \"pretrained_model.layer2.3.bn1.running_mean\", \"pretrained_model.layer2.3.bn1.running_var\", \"pretrained_model.layer2.3.conv2.weight\", \"pretrained_model.layer2.3.bn2.weight\", \"pretrained_model.layer2.3.bn2.bias\", \"pretrained_model.layer2.3.bn2.running_mean\", \"pretrained_model.layer2.3.bn2.running_var\", \"pretrained_model.layer2.3.conv3.weight\", \"pretrained_model.layer2.3.bn3.weight\", \"pretrained_model.layer2.3.bn3.bias\", \"pretrained_model.layer2.3.bn3.running_mean\", \"pretrained_model.layer2.3.bn3.running_var\", \"pretrained_model.layer3.0.conv3.weight\", \"pretrained_model.layer3.0.bn3.weight\", \"pretrained_model.layer3.0.bn3.bias\", \"pretrained_model.layer3.0.bn3.running_mean\", \"pretrained_model.layer3.0.bn3.running_var\", \"pretrained_model.layer3.1.conv3.weight\", \"pretrained_model.layer3.1.bn3.weight\", \"pretrained_model.layer3.1.bn3.bias\", \"pretrained_model.layer3.1.bn3.running_mean\", \"pretrained_model.layer3.1.bn3.running_var\", \"pretrained_model.layer3.2.conv1.weight\", \"pretrained_model.layer3.2.bn1.weight\", \"pretrained_model.layer3.2.bn1.bias\", \"pretrained_model.layer3.2.bn1.running_mean\", \"pretrained_model.layer3.2.bn1.running_var\", \"pretrained_model.layer3.2.conv2.weight\", \"pretrained_model.layer3.2.bn2.weight\", \"pretrained_model.layer3.2.bn2.bias\", \"pretrained_model.layer3.2.bn2.running_mean\", \"pretrained_model.layer3.2.bn2.running_var\", \"pretrained_model.layer3.2.conv3.weight\", \"pretrained_model.layer3.2.bn3.weight\", \"pretrained_model.layer3.2.bn3.bias\", \"pretrained_model.layer3.2.bn3.running_mean\", \"pretrained_model.layer3.2.bn3.running_var\", \"pretrained_model.layer3.3.conv1.weight\", \"pretrained_model.layer3.3.bn1.weight\", \"pretrained_model.layer3.3.bn1.bias\", \"pretrained_model.layer3.3.bn1.running_mean\", \"pretrained_model.layer3.3.bn1.running_var\", \"pretrained_model.layer3.3.conv2.weight\", \"pretrained_model.layer3.3.bn2.weight\", \"pretrained_model.layer3.3.bn2.bias\", \"pretrained_model.layer3.3.bn2.running_mean\", \"pretrained_model.layer3.3.bn2.running_var\", \"pretrained_model.layer3.3.conv3.weight\", \"pretrained_model.layer3.3.bn3.weight\", \"pretrained_model.layer3.3.bn3.bias\", \"pretrained_model.layer3.3.bn3.running_mean\", \"pretrained_model.layer3.3.bn3.running_var\", \"pretrained_model.layer3.4.conv1.weight\", \"pretrained_model.layer3.4.bn1.weight\", \"pretrained_model.layer3.4.bn1.bias\", \"pretrained_model.layer3.4.bn1.running_mean\", \"pretrained_model.layer3.4.bn1.running_var\", \"pretrained_model.layer3.4.conv2.weight\", \"pretrained_model.layer3.4.bn2.weight\", \"pretrained_model.layer3.4.bn2.bias\", \"pretrained_model.layer3.4.bn2.running_mean\", \"pretrained_model.layer3.4.bn2.running_var\", \"pretrained_model.layer3.4.conv3.weight\", \"pretrained_model.layer3.4.bn3.weight\", \"pretrained_model.layer3.4.bn3.bias\", \"pretrained_model.layer3.4.bn3.running_mean\", \"pretrained_model.layer3.4.bn3.running_var\", \"pretrained_model.layer3.5.conv1.weight\", \"pretrained_model.layer3.5.bn1.weight\", \"pretrained_model.layer3.5.bn1.bias\", \"pretrained_model.layer3.5.bn1.running_mean\", \"pretrained_model.layer3.5.bn1.running_var\", \"pretrained_model.layer3.5.conv2.weight\", \"pretrained_model.layer3.5.bn2.weight\", \"pretrained_model.layer3.5.bn2.bias\", \"pretrained_model.layer3.5.bn2.running_mean\", \"pretrained_model.layer3.5.bn2.running_var\", \"pretrained_model.layer3.5.conv3.weight\", \"pretrained_model.layer3.5.bn3.weight\", \"pretrained_model.layer3.5.bn3.bias\", \"pretrained_model.layer3.5.bn3.running_mean\", \"pretrained_model.layer3.5.bn3.running_var\", \"pretrained_model.layer4.0.conv3.weight\", \"pretrained_model.layer4.0.bn3.weight\", \"pretrained_model.layer4.0.bn3.bias\", \"pretrained_model.layer4.0.bn3.running_mean\", \"pretrained_model.layer4.0.bn3.running_var\", \"pretrained_model.layer4.1.conv3.weight\", \"pretrained_model.layer4.1.bn3.weight\", \"pretrained_model.layer4.1.bn3.bias\", \"pretrained_model.layer4.1.bn3.running_mean\", \"pretrained_model.layer4.1.bn3.running_var\", \"pretrained_model.layer4.2.conv1.weight\", \"pretrained_model.layer4.2.bn1.weight\", \"pretrained_model.layer4.2.bn1.bias\", \"pretrained_model.layer4.2.bn1.running_mean\", \"pretrained_model.layer4.2.bn1.running_var\", \"pretrained_model.layer4.2.conv2.weight\", \"pretrained_model.layer4.2.bn2.weight\", \"pretrained_model.layer4.2.bn2.bias\", \"pretrained_model.layer4.2.bn2.running_mean\", \"pretrained_model.layer4.2.bn2.running_var\", \"pretrained_model.layer4.2.conv3.weight\", \"pretrained_model.layer4.2.bn3.weight\", \"pretrained_model.layer4.2.bn3.bias\", \"pretrained_model.layer4.2.bn3.running_mean\", \"pretrained_model.layer4.2.bn3.running_var\", \"pretrained_model.fc.linear0.weight\", \"pretrained_model.fc.linear0.bias\", \"resnet_before_fc.4.0.conv3.weight\", \"resnet_before_fc.4.0.bn3.weight\", \"resnet_before_fc.4.0.bn3.bias\", \"resnet_before_fc.4.0.bn3.running_mean\", \"resnet_before_fc.4.0.bn3.running_var\", \"resnet_before_fc.4.0.downsample.0.weight\", \"resnet_before_fc.4.0.downsample.1.weight\", \"resnet_before_fc.4.0.downsample.1.bias\", \"resnet_before_fc.4.0.downsample.1.running_mean\", \"resnet_before_fc.4.0.downsample.1.running_var\", \"resnet_before_fc.4.1.conv3.weight\", \"resnet_before_fc.4.1.bn3.weight\", \"resnet_before_fc.4.1.bn3.bias\", \"resnet_before_fc.4.1.bn3.running_mean\", \"resnet_before_fc.4.1.bn3.running_var\", \"resnet_before_fc.4.2.conv1.weight\", \"resnet_before_fc.4.2.bn1.weight\", \"resnet_before_fc.4.2.bn1.bias\", \"resnet_before_fc.4.2.bn1.running_mean\", \"resnet_before_fc.4.2.bn1.running_var\", \"resnet_before_fc.4.2.conv2.weight\", \"resnet_before_fc.4.2.bn2.weight\", \"resnet_before_fc.4.2.bn2.bias\", \"resnet_before_fc.4.2.bn2.running_mean\", \"resnet_before_fc.4.2.bn2.running_var\", \"resnet_before_fc.4.2.conv3.weight\", \"resnet_before_fc.4.2.bn3.weight\", \"resnet_before_fc.4.2.bn3.bias\", \"resnet_before_fc.4.2.bn3.running_mean\", \"resnet_before_fc.4.2.bn3.running_var\", \"resnet_before_fc.5.0.conv3.weight\", \"resnet_before_fc.5.0.bn3.weight\", \"resnet_before_fc.5.0.bn3.bias\", \"resnet_before_fc.5.0.bn3.running_mean\", \"resnet_before_fc.5.0.bn3.running_var\", \"resnet_before_fc.5.1.conv3.weight\", \"resnet_before_fc.5.1.bn3.weight\", \"resnet_before_fc.5.1.bn3.bias\", \"resnet_before_fc.5.1.bn3.running_mean\", \"resnet_before_fc.5.1.bn3.running_var\", \"resnet_before_fc.5.2.conv1.weight\", \"resnet_before_fc.5.2.bn1.weight\", \"resnet_before_fc.5.2.bn1.bias\", \"resnet_before_fc.5.2.bn1.running_mean\", \"resnet_before_fc.5.2.bn1.running_var\", \"resnet_before_fc.5.2.conv2.weight\", \"resnet_before_fc.5.2.bn2.weight\", \"resnet_before_fc.5.2.bn2.bias\", \"resnet_before_fc.5.2.bn2.running_mean\", \"resnet_before_fc.5.2.bn2.running_var\", \"resnet_before_fc.5.2.conv3.weight\", \"resnet_before_fc.5.2.bn3.weight\", \"resnet_before_fc.5.2.bn3.bias\", \"resnet_before_fc.5.2.bn3.running_mean\", \"resnet_before_fc.5.2.bn3.running_var\", \"resnet_before_fc.5.3.conv1.weight\", \"resnet_before_fc.5.3.bn1.weight\", \"resnet_before_fc.5.3.bn1.bias\", \"resnet_before_fc.5.3.bn1.running_mean\", \"resnet_before_fc.5.3.bn1.running_var\", \"resnet_before_fc.5.3.conv2.weight\", \"resnet_before_fc.5.3.bn2.weight\", \"resnet_before_fc.5.3.bn2.bias\", \"resnet_before_fc.5.3.bn2.running_mean\", \"resnet_before_fc.5.3.bn2.running_var\", \"resnet_before_fc.5.3.conv3.weight\", \"resnet_before_fc.5.3.bn3.weight\", \"resnet_before_fc.5.3.bn3.bias\", \"resnet_before_fc.5.3.bn3.running_mean\", \"resnet_before_fc.5.3.bn3.running_var\", \"resnet_before_fc.6.0.conv3.weight\", \"resnet_before_fc.6.0.bn3.weight\", \"resnet_before_fc.6.0.bn3.bias\", \"resnet_before_fc.6.0.bn3.running_mean\", \"resnet_before_fc.6.0.bn3.running_var\", \"resnet_before_fc.6.1.conv3.weight\", \"resnet_before_fc.6.1.bn3.weight\", \"resnet_before_fc.6.1.bn3.bias\", \"resnet_before_fc.6.1.bn3.running_mean\", \"resnet_before_fc.6.1.bn3.running_var\", \"resnet_before_fc.6.2.conv1.weight\", \"resnet_before_fc.6.2.bn1.weight\", \"resnet_before_fc.6.2.bn1.bias\", \"resnet_before_fc.6.2.bn1.running_mean\", \"resnet_before_fc.6.2.bn1.running_var\", \"resnet_before_fc.6.2.conv2.weight\", \"resnet_before_fc.6.2.bn2.weight\", \"resnet_before_fc.6.2.bn2.bias\", \"resnet_before_fc.6.2.bn2.running_mean\", \"resnet_before_fc.6.2.bn2.running_var\", \"resnet_before_fc.6.2.conv3.weight\", \"resnet_before_fc.6.2.bn3.weight\", \"resnet_before_fc.6.2.bn3.bias\", \"resnet_before_fc.6.2.bn3.running_mean\", \"resnet_before_fc.6.2.bn3.running_var\", \"resnet_before_fc.6.3.conv1.weight\", \"resnet_before_fc.6.3.bn1.weight\", \"resnet_before_fc.6.3.bn1.bias\", \"resnet_before_fc.6.3.bn1.running_mean\", \"resnet_before_fc.6.3.bn1.running_var\", \"resnet_before_fc.6.3.conv2.weight\", \"resnet_before_fc.6.3.bn2.weight\", \"resnet_before_fc.6.3.bn2.bias\", \"resnet_before_fc.6.3.bn2.running_mean\", \"resnet_before_fc.6.3.bn2.running_var\", \"resnet_before_fc.6.3.conv3.weight\", \"resnet_before_fc.6.3.bn3.weight\", \"resnet_before_fc.6.3.bn3.bias\", \"resnet_before_fc.6.3.bn3.running_mean\", \"resnet_before_fc.6.3.bn3.running_var\", \"resnet_before_fc.6.4.conv1.weight\", \"resnet_before_fc.6.4.bn1.weight\", \"resnet_before_fc.6.4.bn1.bias\", \"resnet_before_fc.6.4.bn1.running_mean\", \"resnet_before_fc.6.4.bn1.running_var\", \"resnet_before_fc.6.4.conv2.weight\", \"resnet_before_fc.6.4.bn2.weight\", \"resnet_before_fc.6.4.bn2.bias\", \"resnet_before_fc.6.4.bn2.running_mean\", \"resnet_before_fc.6.4.bn2.running_var\", \"resnet_before_fc.6.4.conv3.weight\", \"resnet_before_fc.6.4.bn3.weight\", \"resnet_before_fc.6.4.bn3.bias\", \"resnet_before_fc.6.4.bn3.running_mean\", \"resnet_before_fc.6.4.bn3.running_var\", \"resnet_before_fc.6.5.conv1.weight\", \"resnet_before_fc.6.5.bn1.weight\", \"resnet_before_fc.6.5.bn1.bias\", \"resnet_before_fc.6.5.bn1.running_mean\", \"resnet_before_fc.6.5.bn1.running_var\", \"resnet_before_fc.6.5.conv2.weight\", \"resnet_before_fc.6.5.bn2.weight\", \"resnet_before_fc.6.5.bn2.bias\", \"resnet_before_fc.6.5.bn2.running_mean\", \"resnet_before_fc.6.5.bn2.running_var\", \"resnet_before_fc.6.5.conv3.weight\", \"resnet_before_fc.6.5.bn3.weight\", \"resnet_before_fc.6.5.bn3.bias\", \"resnet_before_fc.6.5.bn3.running_mean\", \"resnet_before_fc.6.5.bn3.running_var\", \"resnet_before_fc.7.0.conv3.weight\", \"resnet_before_fc.7.0.bn3.weight\", \"resnet_before_fc.7.0.bn3.bias\", \"resnet_before_fc.7.0.bn3.running_mean\", \"resnet_before_fc.7.0.bn3.running_var\", \"resnet_before_fc.7.1.conv3.weight\", \"resnet_before_fc.7.1.bn3.weight\", \"resnet_before_fc.7.1.bn3.bias\", \"resnet_before_fc.7.1.bn3.running_mean\", \"resnet_before_fc.7.1.bn3.running_var\", \"resnet_before_fc.7.2.conv1.weight\", \"resnet_before_fc.7.2.bn1.weight\", \"resnet_before_fc.7.2.bn1.bias\", \"resnet_before_fc.7.2.bn1.running_mean\", \"resnet_before_fc.7.2.bn1.running_var\", \"resnet_before_fc.7.2.conv2.weight\", \"resnet_before_fc.7.2.bn2.weight\", \"resnet_before_fc.7.2.bn2.bias\", \"resnet_before_fc.7.2.bn2.running_mean\", \"resnet_before_fc.7.2.bn2.running_var\", \"resnet_before_fc.7.2.conv3.weight\", \"resnet_before_fc.7.2.bn3.weight\", \"resnet_before_fc.7.2.bn3.bias\", \"resnet_before_fc.7.2.bn3.running_mean\", \"resnet_before_fc.7.2.bn3.running_var\", \"downsampled_model.linear0.weight\", \"downsampled_model.linear0.bias\", \"intermediate_genus_model.linear0.weight\", \"intermediate_genus_model.linear0.bias\", \"genus_fc.linear0.weight\", \"genus_fc.linear0.bias\". \n\tUnexpected key(s) in state_dict: \"module_list.0.fc.weight\", \"module_list.0.fc.bias\", \"module_list.2.weight\", \"module_list.2.bias\", \"module_list.3.weight\", \"module_list.3.bias\", \"module_list.4.0.weight\", \"module_list.4.0.bias\", \"pretrained_model.fc.weight\", \"pretrained_model.fc.bias\", \"downsampled_model.weight\", \"downsampled_model.bias\", \"intermediate_genus_model.weight\", \"intermediate_genus_model.bias\", \"genus_fc.0.weight\", \"genus_fc.0.bias\". \n\tsize mismatch for module_list.0.layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for module_list.0.layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for module_list.0.layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for module_list.0.layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for module_list.0.layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.0.layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.0.layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.0.layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.0.layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for module_list.0.layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for module_list.0.layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for module_list.0.layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.0.layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.0.layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.0.layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.0.layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for module_list.0.layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for module_list.0.layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for module_list.0.layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for module_list.0.layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for module_list.0.layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for module_list.0.layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for module_list.0.layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n\tsize mismatch for module_list.1.4.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for module_list.1.4.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for module_list.1.5.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for module_list.1.5.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for module_list.1.5.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.1.5.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.1.5.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.1.5.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.1.5.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for module_list.1.6.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for module_list.1.6.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for module_list.1.6.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.1.6.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.1.6.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.1.6.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.1.6.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for module_list.1.7.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for module_list.1.7.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for module_list.1.7.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for module_list.1.7.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for module_list.1.7.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for module_list.1.7.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for module_list.1.7.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n\tsize mismatch for pretrained_model.layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for pretrained_model.layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for pretrained_model.layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for pretrained_model.layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for pretrained_model.layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for pretrained_model.layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for pretrained_model.layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for pretrained_model.layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for pretrained_model.layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for pretrained_model.layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for pretrained_model.layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for pretrained_model.layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for pretrained_model.layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for pretrained_model.layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for pretrained_model.layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for pretrained_model.layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for pretrained_model.layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for pretrained_model.layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for pretrained_model.layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for pretrained_model.layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for pretrained_model.layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for pretrained_model.layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for pretrained_model.layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n\tsize mismatch for resnet_before_fc.4.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for resnet_before_fc.4.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for resnet_before_fc.5.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for resnet_before_fc.5.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for resnet_before_fc.5.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for resnet_before_fc.5.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for resnet_before_fc.5.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for resnet_before_fc.5.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for resnet_before_fc.5.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for resnet_before_fc.6.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for resnet_before_fc.6.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for resnet_before_fc.6.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for resnet_before_fc.6.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for resnet_before_fc.6.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for resnet_before_fc.6.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for resnet_before_fc.6.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for resnet_before_fc.7.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for resnet_before_fc.7.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for resnet_before_fc.7.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for resnet_before_fc.7.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for resnet_before_fc.7.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for resnet_before_fc.7.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for resnet_before_fc.7.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6ead811200cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasetManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLoaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetModelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrialName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_elapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrialName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model {0} loaded!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrialName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/melhamodenv3/BGNN/CNN.py\u001b[0m in \u001b[0;36mloadModel\u001b[0;34m(model, savedModelName)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msavedModelName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavedModelName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCheckpointNameFinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0mvalidation_accuracy_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/melhamodenv3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CNN_heirarchy:\n\tMissing key(s) in state_dict: \"module_list.0.layer1.0.conv3.weight\", \"module_list.0.layer1.0.bn3.weight\", \"module_list.0.layer1.0.bn3.bias\", \"module_list.0.layer1.0.bn3.running_mean\", \"module_list.0.layer1.0.bn3.running_var\", \"module_list.0.layer1.0.downsample.0.weight\", \"module_list.0.layer1.0.downsample.1.weight\", \"module_list.0.layer1.0.downsample.1.bias\", \"module_list.0.layer1.0.downsample.1.running_mean\", \"module_list.0.layer1.0.downsample.1.running_var\", \"module_list.0.layer1.1.conv3.weight\", \"module_list.0.layer1.1.bn3.weight\", \"module_list.0.layer1.1.bn3.bias\", \"module_list.0.layer1.1.bn3.running_mean\", \"module_list.0.layer1.1.bn3.running_var\", \"module_list.0.layer1.2.conv1.weight\", \"module_list.0.layer1.2.bn1.weight\", \"module_list.0.layer1.2.bn1.bias\", \"module_list.0.layer1.2.bn1.running_mean\", \"module_list.0.layer1.2.bn1.running_var\", \"module_list.0.layer1.2.conv2.weight\", \"module_list.0.layer1.2.bn2.weight\", \"module_list.0.layer1.2.bn2.bias\", \"module_list.0.layer1.2.bn2.running_mean\", \"module_list.0.layer1.2.bn2.running_var\", \"module_list.0.layer1.2.conv3.weight\", \"module_list.0.layer1.2.bn3.weight\", \"module_list.0.layer1.2.bn3.bias\", \"module_list.0.layer1.2.bn3.running_mean\", \"module_list.0.layer1.2.bn3.running_var\", \"module_list.0.layer2.0.conv3.weight\", \"module_list.0.layer2.0.bn3.weight\", \"module_list.0.layer2.0.bn3.bias\", \"module_list.0.layer2.0.bn3.running_mean\", \"module_list.0.layer2.0.bn3.running_var\", \"module_list.0.layer2.1.conv3.weight\", \"module_list.0.layer2.1.bn3.weight\", \"module_list.0.layer2.1.bn3.bias\", \"module_list.0.layer2.1.bn3.running_mean\", \"module_list.0.layer2.1.bn3.running_var\", \"module_list.0.layer2.2.conv1.weight\", \"module_list.0.layer2.2.bn1.weight\", \"module_list.0.layer2.2.bn1.bias\", \"module_list.0.layer2.2.bn1.running_mean\", \"module_list.0.layer2.2.bn1.running_var\", \"module_list.0.layer2.2.conv2.weight\", \"module_list.0.layer2.2.bn2.weight\", \"module_list.0.layer2.2.bn2.bias\", \"module_list.0.layer2.2.bn2.running_mean\", \"module_list.0.layer2.2.bn2.running_var\", \"module_list.0.layer2.2.conv3.weight\", \"module_list.0.layer2.2.bn3.weight\", \"module_list.0.layer2.2.bn3.bias\", \"module_list.0.layer2.2.bn3.running_mean\", \"module_list.0.layer2.2.bn3.running_var\", \"module_list.0.layer2.3.conv1.weight\", \"module_list.0.layer2.3.bn1.weight\", \"module_list.0.layer2.3.bn1.bias\", \"module_list.0.layer2.3.bn1.running_mean\", \"module_list.0.layer2.3.bn1.running_var\", \"module_list.0.layer2.3.conv2.weight\", \"module_list.0.layer2.3.bn2.weight\", \"module_list.0.layer2.3.bn2.bias\", \"module_list.0.layer2.3.bn2.running_mean\", \"module_list.0.layer2.3.bn2.running_var\", \"module_list.0.layer2.3.conv3.weight\", \"module_list.0.layer2.3.bn3.weight\", \"module_list.0.layer2.3.bn3.bias\", \"module_list.0.layer2.3.bn3.running_mean\", \"module_list.0.layer2.3.bn3.running_var\", \"module_list.0.layer3.0.conv3.weight\", \"module_list.0.layer3.0.bn3.weight\", \"module_list.0.layer3.0.bn3.bias\", \"module_list.0.layer3.0.bn3.running_mean\", \"module_list.0.layer3.0.bn3.running_var\", \"module_list.0.layer3.1.conv3.weight\", \"module_list.0.layer3.1.bn3.weight\", \"module_list.0.layer3.1.bn3.bias\", \"module_list.0.layer3.1.bn3.running_mean\", \"module_list.0.layer3.1.bn3.running_var\", \"module_list.0.layer3.2.conv1.weight\", \"module_list.0.layer3.2.bn1.weight\", \"module_list.0.layer3.2.bn1.bias\", \"module_list.0.layer3.2.bn1.running_mean\", \"module_list.0.layer3.2.bn1.running_var\", \"module_list.0.layer3.2.conv2.weight\", \"module_list.0.layer3.2.bn2.weight\", \"module_list.0.layer3.2.bn2.bias\", \"module_list.0.layer3.2.bn2.running_mean\", \"module_list.0.layer3.2.bn2.running_var\", \"module_list.0.layer3.2.conv3.weight\", \"module_list.0.layer3.2.bn3.weight\", \"module_list.0.layer3.2.bn3.bias\", \"module_list.0.layer3.2.bn3.running_mean\", \"module_list.0.layer3.2.bn3.running_var\", \"module_list.0.layer3.3.conv1.weight\", \"module_list.0.layer3.3.bn1.weight\", \"module_list.0.layer3.3.bn1.bias\", \"module_list.0.layer3.3.bn1.running_mean\", \"module_list.0.layer3.3.bn1.running_var\", \"module_list.0.layer3.3.conv2.weight\", \"module_list.0.layer3.3.bn2.weight\", \"module_list.0.layer3.3.bn2.bias\", \"module_list.0.layer3.3.bn2.running_mean\", \"module_list.0.layer3.3.bn2.running_var\", \"module_list.0.layer3.3.conv3.weight\", \"module_list.0.layer3.3.bn3.weight\", \"module_list.0.layer3.3.bn3.bias\", \"module_list.0.layer3.3.bn3.running_mean\", \"module_list.0.layer3.3.bn3.running_var\", \"module_list.0.layer3.4.conv1.weight\", \"module_list.0.layer3.4.bn1.weight\", \"module_list.0.layer3.4.bn1.bias\", \"module_list.0.layer3.4.bn1.running_mean\", \"module_list.0.layer3.4.bn1.running_var\", \"module_list.0.layer3.4.conv2.weight\", \"module_list.0.layer3.4.bn2.weight\", \"module_list.0.layer3.4.bn2.bias\", \"module_list.0.layer3.4.bn2.running_mean\", \"module_list.0.layer3.4.bn2.running_var\", \"module_list.0.layer3.4.conv3.weight\", \"module_list.0.layer3.4.bn3.weight\", \"module_list.0.layer3.4.bn3.bias\", \"module_list.0.layer3.4.bn3.running_mean\", \"module_list.0.layer3.4.bn3.running_var\", \"module_list.0.layer3.5.conv1.weight\", \"module_list.0.layer3.5.bn1.weight\", \"module_list.0.layer3.5.bn1.bias\", \"module_list.0.layer3.5.bn1.running_mean\", \"module_list.0.layer3.5.bn1.running_var\", \"module_list.0.layer3.5.conv2.weight\", \"module_list.0.layer3.5.bn2.weight\", \"module_list.0.layer3.5.bn2.bias\", \"module_list.0.layer3.5.bn2.running_mean\", \"module_list.0.layer3.5.bn2.running_var\", \"module_list.0.layer3.5.conv3.weight\", \"module_list.0.layer3.5.bn3.weight\", \"module_list.0.layer3.5.bn3.bias\", \"module_list.0.layer3.5.bn3.running_mean\", \"module_list.0.layer3.5.bn3.running_var\", \"module_list.0.layer4.0.conv3.weight\", \"module_list.0.layer4.0.bn3.weight\", \"module_list.0.layer4.0.bn3.bias\", \"module_list.0.layer4.0.bn3.running_mean\", \"module_list.0.layer4.0.bn3.running_var\", \"module_list.0.layer4.1.conv3.weight\", \"module_list.0.layer4.1.bn3.weight\", \"module_list.0.layer4.1.bn3.bias\", \"module_list.0.layer4.1.bn3.running_mean\", \"module_list.0.layer4.1.bn3.running_var\", \"module_list.0.layer4.2.conv1.weight\", \"module_list.0.layer4.2.bn1.weight\", \"module_list.0.layer4.2.bn1.bias\", \"module_list.0.layer4.2.bn1.running_mean\", \"module_list.0.layer4.2.bn1.running_var\", \"module_list.0.layer4.2.conv2.weight\", \"module_list.0.layer4.2.bn2.weight\", \"module_list.0.layer4.2.bn2.bias\", \"module_list.0.layer4.2.bn2.running_mean\", \"module_list.0.layer4.2.bn2.running_var\", \"module_list.0.layer4.2.conv3.weight\", \"module_list.0.layer4.2.bn3.weight\", \"module_list.0.layer4.2.bn3.bias\", \"module_list.0.layer4.2.bn3.running_mean\", \"module_list.0.layer4.2.bn3.running_var\", \"module_list.0.fc.linear0.weight\", \"module_list.0.fc.linear0.bias\", \"module_list.1.4.0.conv3.weight\", \"module_list.1.4.0.bn3.weight\", \"module_list.1.4.0.bn3.bias\", \"module_list.1.4.0.bn3.running_mean\", \"module_list.1.4.0.bn3.running_var\", \"module_list.1.4.0.downsample.0.weight\", \"module_list.1.4.0.downsample.1.weight\", \"module_list.1.4.0.downsample.1.bias\", \"module_list.1.4.0.downsample.1.running_mean\", \"module_list.1.4.0.downsample.1.running_var\", \"module_list.1.4.1.conv3.weight\", \"module_list.1.4.1.bn3.weight\", \"module_list.1.4.1.bn3.bias\", \"module_list.1.4.1.bn3.running_mean\", \"module_list.1.4.1.bn3.running_var\", \"module_list.1.4.2.conv1.weight\", \"module_list.1.4.2.bn1.weight\", \"module_list.1.4.2.bn1.bias\", \"module_list.1.4.2.bn1.running_mean\", \"module_list.1.4.2.bn1.running_var\", \"module_list.1.4.2.conv2.weight\", \"module_list.1.4.2.bn2.weight\", \"module_list.1.4.2.bn2.bias\", \"module_list.1.4.2.bn2.running_mean\", \"module_list.1.4.2.bn2.running_var\", \"module_list.1.4.2.conv3.weight\", \"module_list.1.4.2.bn3.weight\", \"module_list.1.4.2.bn3.bias\", \"module_list.1.4.2.bn3.running_mean\", \"module_list.1.4.2.bn3.running_var\", \"module_list.1.5.0.conv3.weight\", \"module_list.1.5.0.bn3.weight\", \"module_list.1.5.0.bn3.bias\", \"module_list.1.5.0.bn3.running_mean\", \"module_list.1.5.0.bn3.running_var\", \"module_list.1.5.1.conv3.weight\", \"module_list.1.5.1.bn3.weight\", \"module_list.1.5.1.bn3.bias\", \"module_list.1.5.1.bn3.running_mean\", \"module_list.1.5.1.bn3.running_var\", \"module_list.1.5.2.conv1.weight\", \"module_list.1.5.2.bn1.weight\", \"module_list.1.5.2.bn1.bias\", \"module_list.1.5.2.bn1.running_mean\", \"module_list.1.5.2.bn1.running_var\", \"module_list.1.5.2.conv2.weight\", \"module_list.1.5.2.bn2.weight\", \"module_list.1.5.2.bn2.bias\", \"module_list.1.5.2.bn2.running_mean\", \"module_list.1.5.2.bn2.running_var\", \"module_list.1.5.2.conv3.weight\", \"module_list.1.5.2.bn3.weight\", \"module_list.1.5.2.bn3.bias\", \"module_list.1.5.2.bn3.running_mean\", \"module_list.1.5.2.bn3.running_var\", \"module_list.1.5.3.conv1.weight\", \"module_list.1.5.3.bn1.weight\", \"module_list.1.5.3.bn1.bias\", \"module_list.1.5.3.bn1.running_mean\", \"module_list.1.5.3.bn1.running_var\", \"module_list.1.5.3.conv2.weight\", \"module_list.1.5.3.bn2.weight\", \"module_list.1.5.3.bn2.bias\", \"module_list.1.5.3.bn2.running_mean\", \"module_list.1.5.3.bn2.running_var\", \"module_list.1.5.3.conv3.weight\", \"module_list.1.5.3.bn3.weight\", \"module_list.1.5.3.bn3.bias\", \"module_list.1.5.3.bn3.running_mean\", \"module_list.1.5.3.bn3.running_var\", \"module_list.1.6.0.conv3.weight\", \"module_list.1.6.0.bn3.weight\", \"module_list.1.6.0.bn3.bias\", \"module_list.1.6.0.bn3.running_mean\", \"module_list.1.6.0.bn3.running_var\", \"module_list.1.6.1.conv3.weight\", \"module_list.1.6.1.bn3.weight\", \"module_list.1.6.1.bn3.bias\", \"module_list.1.6.1.bn3.running_mean\", \"module_list.1.6.1.bn3.running_var\", \"module_list.1.6.2.conv1.weight\", \"module_list.1.6.2.bn1.weight\", \"module_list.1.6.2.bn1.bias\", \"module_list.1.6.2.bn1.running_mean\", \"module_list.1.6.2.bn1.running_var\", \"module_list.1.6.2.conv2.weight\", \"module_list.1.6.2.bn2.weight\", \"module_list.1.6.2.bn2.bias\", \"module_list.1.6.2.bn2.running_mean\", \"module_list.1.6.2.bn2.running_var\", \"module_list.1.6.2.conv3.weight\", \"module_list.1.6.2.bn3.weight\", \"module_list.1.6.2.bn3.bias\", \"module_list.1.6.2.bn3.running_mean\", \"module_list.1.6.2.bn3.running_var\", \"module_list.1.6.3.conv1.weight\", \"module_list.1.6.3.bn1.weight\", \"module_list.1.6.3.bn1.bias\", \"module_list.1.6.3.bn1.running_mean\", \"module_list.1.6.3.bn1.running_var\", \"module_list.1.6.3.conv2.weight\", \"module_list.1.6.3.bn2.weight\", \"module_list.1.6.3.bn2.bias\", \"module_list.1.6.3.bn2.running_mean\", \"module_list.1.6.3.bn2.running_var\", \"module_list.1.6.3.conv3.weight\", \"module_list.1.6.3.bn3.weight\", \"module_list.1.6.3.bn3.bias\", \"module_list.1.6.3.bn3.running_mean\", \"module_list.1.6.3.bn3.running_var\", \"module_list.1.6.4.conv1.weight\", \"module_list.1.6.4.bn1.weight\", \"module_list.1.6.4.bn1.bias\", \"module_list.1.6.4.bn1.running_mean\", \"module_list.1.6.4.bn1.running_var\", \"module_list.1.6.4.conv2.weight\", \"module_list.1.6.4.bn2.weight\", \"module_list.1.6.4.bn2.bias\", \"module_list.1.6.4.bn2.running_mean\", \"module_list.1.6.4.bn2.running_var\", \"module_list.1.6.4.conv3.weight\", \"module_list.1.6.4.bn3.weight\", \"module_list.1.6.4.bn3.bias\", \"module_list.1.6.4.bn3.running_mean\", \"module_list.1.6.4.bn3.running_var\", \"module_list.1.6.5.conv1.weight\", \"module_list.1.6.5.bn1.weight\", \"module_list.1.6.5.bn1.bias\", \"module_list.1.6.5.bn1.running_mean\", \"module_list.1.6.5.bn1.running_var\", \"module_list.1.6.5.conv2.weight\", \"module_list.1.6.5.bn2.weight\", \"module_list.1.6.5.bn2.bias\", \"module_list.1.6.5.bn2.running_mean\", \"module_list.1.6.5.bn2.running_var\", \"module_list.1.6.5.conv3.weight\", \"module_list.1.6.5.bn3.weight\", \"module_list.1.6.5.bn3.bias\", \"module_list.1.6.5.bn3.running_mean\", \"module_list.1.6.5.bn3.running_var\", \"module_list.1.7.0.conv3.weight\", \"module_list.1.7.0.bn3.weight\", \"module_list.1.7.0.bn3.bias\", \"module_list.1.7.0.bn3.running_mean\", \"module_list.1.7.0.bn3.running_var\", \"module_list.1.7.1.conv3.weight\", \"module_list.1.7.1.bn3.weight\", \"module_list.1.7.1.bn3.bias\", \"module_list.1.7.1.bn3.running_mean\", \"module_list.1.7.1.bn3.running_var\", \"module_list.1.7.2.conv1.weight\", \"module_list.1.7.2.bn1.weight\", \"module_list.1.7.2.bn1.bias\", \"module_list.1.7.2.bn1.running_mean\", \"module_list.1.7.2.bn1.running_var\", \"module_list.1.7.2.conv2.weight\", \"module_list.1.7.2.bn2.weight\", \"module_list.1.7.2.bn2.bias\", \"module_list.1.7.2.bn2.running_mean\", \"module_list.1.7.2.bn2.running_var\", \"module_list.1.7.2.conv3.weight\", \"module_list.1.7.2.bn3.weight\", \"module_list.1.7.2.bn3.bias\", \"module_list.1.7.2.bn3.running_mean\", \"module_list.1.7.2.bn3.running_var\", \"module_list.2.linear0.weight\", \"module_list.2.linear0.bias\", \"module_list.3.linear0.weight\", \"module_list.3.linear0.bias\", \"module_list.4.linear0.weight\", \"module_list.4.linear0.bias\", \"pretrained_model.layer1.0.conv3.weight\", \"pretrained_model.layer1.0.bn3.weight\", \"pretrained_model.layer1.0.bn3.bias\", \"pretrained_model.layer1.0.bn3.running_mean\", \"pretrained_model.layer1.0.bn3.running_var\", \"pretrained_model.layer1.0.downsample.0.weight\", \"pretrained_model.layer1.0.downsample.1.weight\", \"pretrained_model.layer1.0.downsample.1.bias\", \"pretrained_model.layer1.0.downsample.1.running_mean\", \"pretrained_model.layer1.0.downsample.1.running_var\", \"pretrained_model.layer1.1.conv3.weight\", \"pretrained_model.layer1.1.bn3.weight\", \"pretrained_model.layer1.1.bn3.bias\", \"pretrained_model.layer1.1.bn3.running_mean\", \"pretrained_model.layer1.1.bn3.running_var\", \"pretrained_model.layer1.2.conv1.weight\", \"pretrained_model.layer1.2.bn1.weight\", \"pretrained_model.layer1.2.bn1.bias\", \"pretrained_model.layer1.2.bn1.running_mean\", \"pretrained_model.layer1.2.bn1.running_var\", \"pretrained_model.layer1.2.conv2.weight\", \"pretrained_model.layer1.2.bn2.weight\", \"pretrained_model.layer1.2.bn2.bias\", \"pretrained_model.layer1.2.bn2.running_mean\", \"pretrained_model.layer1.2.bn2.running_var\", \"pretrained_model.layer1.2.conv3.weight\", \"pretrained_model.layer1.2.bn3.weight\", \"pretrained_model.layer1.2.bn3.bias\", \"pretrained_model.layer1.2.bn3.running_mean\", \"pretrained_model.layer1.2.bn3.running_var\", \"pretrained_model.layer2.0.conv3.weight\", \"pretrained_model.layer2.0.bn3.weight\", \"pretrained_model.layer2.0.bn3.bias\", \"pretrained_model.layer2.0.bn3.running_mean\", \"pretrained_model.layer2.0.bn3.running_var\", \"pretrained_model.layer2.1.conv3.weight\", \"pretrained_model.layer2.1.bn3.weight\", \"pretrained_model.layer2.1.bn3.bias\", \"pretrained_model.layer2.1.bn3.running_mean\", \"pretrained_model.layer2.1.bn3.running_var\", \"pretrained_model.layer2.2.conv1.weight\", \"pretrained_model.layer2.2.bn1.weight\", \"pretrained_model.layer2.2.bn1.bias\", \"pretrained_model.layer2.2.bn1.running_mean\", \"pretrained_model.layer2.2.bn1.running_var\", \"pretrained_model.layer2.2.conv2.weight\", \"pretrained_model.layer2.2.bn2.weight\", \"pretrained_model.layer2.2.bn2.bias\", \"pretrained_model.layer2.2.bn2.running_mean\", \"pretrained_model.layer2.2.bn2.running_var\", \"pretrained_model.layer2.2.conv3.weight\", \"pretrained_model.layer2.2.bn3.weight\", \"pretrained_model.layer2.2.bn3.bias\", \"pretrained_model.layer2.2.bn3.running_mean\", \"pretrained_model.layer2.2.bn3.running_var\", \"pretrained_model.layer2.3.conv1.weight\", \"pretrained_model.layer2.3.bn1.weight\", \"pretrained_model.layer2.3.bn1.bias\", \"pretrained_model.layer2.3.bn1.running_mean\", \"pretrained_model.layer2.3.bn1.running_var\", \"pretrained_model.layer2.3.conv2.weight\", \"pretrained_model.layer2.3.bn2.weight\", \"pretrained_model.layer2.3.bn2.bias\", \"pretrained_model.layer2.3.bn2.running_mean\", \"pretrained_model.layer2.3.bn2.running_var\", \"pretrained_model.layer2.3.conv3.weight\", \"pretrained_model.layer2.3.bn3.weight\", \"pretrained_model.layer2.3.bn3.bias\", \"pretrained_model.layer2.3.bn3.running_mean\", \"pretrained_model.layer2.3.bn3.running_var\", \"pretrained_model.layer3.0.conv3.weight\", \"pretrained_model.layer3.0.bn3.weight\", \"pretrained_model.layer3.0.bn3.bias\", \"pretrained_model.layer3.0.bn3.running_mean\", \"pretrained_model.layer3.0.bn3.running_var\", \"pretrained_model.layer3.1.conv3.weight\", \"pretrained_model.layer3.1.bn3.weight\", \"pretrained_model.layer3.1.bn3.bias\", \"pretrained_model.layer3.1.bn3.running_mean\", \"pretrained_model.layer3.1.bn3.running_var\", \"pretrained_model.layer3.2.conv1.weight\", \"pretrained_model.layer3.2.bn1.weight\", \"pretrained_model.layer3.2.bn1.bias\", \"pretrained_model.layer3.2.bn1.running_mean\", \"pretrained_model.layer3.2.bn1.running_var\", \"pretrained_model.layer3.2.conv2.weight\", \"pretrained_model.layer3.2.bn2.weight\", \"pretrained_model.layer3.2.bn2.bias\", \"pretrained_model.layer3.2.bn2.running_mean\", \"pretrained_model.layer3.2.bn2.running_var\", \"pretrained_model.layer3.2.conv3.weight\", \"pretrained_model.layer3.2.bn3.weight\", \"pretrained_model.layer3.2.bn3.bias\", \"pretrained_model.layer3.2.bn3.running_mean\", \"pretrained_model.layer3.2.bn3.running_var\", \"pretrained_model.layer3.3.conv1.weight\", \"pretrained_model.layer3.3.bn1.weight\", \"pretrained_model.layer3.3.bn1.bias\", \"pretrained_model.layer3.3.bn1.running_mean\", \"pretrained_model.layer3.3.bn1.running_var\", \"pretrained_model.layer3.3.conv2.weight\", \"pretrained_model.layer3.3.bn2.weight\", \"pretrained_model.layer3.3.bn2.bias\", \"pretrained_model.layer3.3.bn2.running_mean\", \"pretrained_model.layer3.3.bn2.running_var\", \"pretrained_model.layer3.3.conv3.weight\", \"pretrained_model.layer3.3.bn3.weight\", \"pretrained_model.layer3.3.bn3.bias\", \"pretrained_model.layer3.3.bn3.running_mean\", \"pretrained_model.layer3.3.bn3.running_var\", \"pretrained_model.layer3.4.conv1.weight\", \"pretrained_model.layer3.4.bn1.weight\", \"pretrained_model.layer3.4.bn1.bias\", \"pretrained_model.layer3.4.bn1.running_mean\", \"pretrained_model.layer3.4.bn1.running_var\", \"pretrained_model.layer3.4.conv2.weight\", \"pretrained_model.layer3.4.bn2.weight\", \"pretrained_model.layer3.4.bn2.bias\", \"pretrained_model.layer3.4.bn2.running_mean\", \"pretrained_model.layer3.4.bn2.running_var\", \"pretrained_model.layer3.4.conv3.weight\", \"pretrained_model.layer3.4.bn3.weight\", \"pretrained_model.layer3.4.bn3.bias\", \"pretrained_model.layer3.4.bn3.running_mean\", \"pretrained_model.layer3.4.bn3.running_var\", \"pretrained_model.layer3.5.conv1.weight\", \"pretrained_model.layer3.5.bn1.weight\", \"pretrained_model.layer3.5.bn1.bias\", \"pretrained_model.layer3.5.bn1.running_mean\", \"pretrained_model.layer3.5.bn1.running_var\", \"pretrained_model.layer3.5.conv2.weight\", \"pretrained_model.layer3.5.bn2.weight\", \"pretrained_model.layer3.5.bn2.bias\", \"pretrained_model.layer3.5.bn2.running_mean\", \"pretrained_model.layer3.5.bn2.running_var\", \"pretrained_model.layer3.5.conv3.weight\", \"pretrained_model.layer3.5.bn3.weight\", \"pretrained_model.layer3.5.bn3.bias\", \"pretrained_model.layer3.5.bn3.running_mean\", \"pretrained_model.layer3.5.bn3.running_var\", \"pretrained_model.layer4.0.conv3.weight\", \"pretrained_model.layer4.0.bn3.weight\", \"pretrained_model.layer4.0.bn3.bias\", \"pretrained_model.layer4.0.bn3.running_mean\", \"pretrained_model.layer4.0.bn3.running_var\", \"pretrained_model.layer4.1.conv3.weight\", \"pretrained_model.layer4.1.bn3.weight\", \"pretrained_model.layer4.1.bn3.bias\", \"pretrained_model.layer4.1.bn3.running_mean\", \"pretrained_model.layer4.1.bn3.running_var\", \"pretrained_model.layer4.2.conv1.weight\", \"pretrained_model.layer4.2.bn1.weight\", \"pretrained_model.layer4.2.bn1.bias\", \"pretrained_model.layer4.2.bn1.running_mean\", \"pretrained_model.layer4.2.bn1.running_var\", \"pretrained_model.layer4.2.conv2.weight\", \"pretrained_model.layer4.2.bn2.weight\", \"pretrained_model.layer4.2.bn2.bias\", \"pretrained_model.layer4.2.bn2.running_mean\", \"pretrained_model.layer4.2.bn2.running_var\", \"pretrained_model.layer4.2.conv3.weight\", \"pretrained_model.layer4.2.bn3.weight\", \"pretrained_model.layer4.2.bn3.bias\", \"pretrained_model.layer4.2.bn3.running_mean\", \"pretrained_model.layer4.2.bn3.running_var\", \"pretrained_model.fc.linear0.weight\", \"pretrained_model.fc.linear0.bias\", \"resnet_before_fc.4.0.conv3.weight\", \"resnet_before_fc.4.0.bn3.weight\", \"resnet_before_fc.4.0.bn3.bias\", \"resnet_before_fc.4.0.bn3.running_mean\", \"resnet_before_fc.4.0.bn3.running_var\", \"resnet_before_fc.4.0.downsample.0.weight\", \"resnet_before_fc.4.0.downsample.1.weight\", \"resnet_before_fc.4.0.downsample.1.bias\", \"resnet_before_fc.4.0.downsample.1.running_mean\", \"resnet_before_fc.4.0.downsample.1.running_var\", \"resnet_before_fc.4.1.conv3.weight\", \"resnet_before_fc.4.1.bn3.weight\", \"resnet_before_fc.4.1.bn3.bias\", \"resnet_before_fc.4.1.bn3.running_mean\", \"resnet_before_fc.4.1.bn3.running_var\", \"resnet_before_fc.4.2.conv1.weight\", \"resnet_before_fc.4.2.bn1.weight\", \"resnet_before_fc.4.2.bn1.bias\", \"resnet_before_fc.4.2.bn1.running_mean\", \"resnet_before_fc.4.2.bn1.running_var\", \"resnet_before_fc.4.2.conv2.weight\", \"resnet_before_fc.4.2.bn2.weight\", \"resnet_before_fc.4.2.bn2.bias\", \"resnet_before_fc.4.2.bn2.running_mean\", \"resnet_before_fc.4.2.bn2.running_var\", \"resnet_before_fc.4.2.conv3.weight\", \"resnet_before_fc.4.2.bn3.weight\", \"resnet_before_fc.4.2.bn3.bias\", \"resnet_before_fc.4.2.bn3.running_mean\", \"resnet_before_fc.4.2.bn3.running_var\", \"resnet_before_fc.5.0.conv3.weight\", \"resnet_before_fc.5.0.bn3.weight\", \"resnet_before_fc.5.0.bn3.bias\", \"resnet_before_fc.5.0.bn3.running_mean\", \"resnet_before_fc.5.0.bn3.running_var\", \"resnet_before_fc.5.1.conv3.weight\", \"resnet_before_fc.5.1.bn3.weight\", \"resnet_before_fc.5.1.bn3.bias\", \"resnet_before_fc.5.1.bn3.running_mean\", \"resnet_before_fc.5.1.bn3.running_var\", \"resnet_before_fc.5.2.conv1.weight\", \"resnet_before_fc.5.2.bn1.weight\", \"resnet_before_fc.5.2.bn1.bias\", \"resnet_before_fc.5.2.bn1.running_mean\", \"resnet_before_fc.5.2.bn1.running_var\", \"resnet_before_fc.5.2.conv2.weight\", \"resnet_before_fc.5.2.bn2.weight\", \"resnet_before_fc.5.2.bn2.bias\", \"resnet_before_fc.5.2.bn2.running_mean\", \"resnet_before_fc.5.2.bn2.running_var\", \"resnet_before_fc.5.2.conv3.weight\", \"resnet_before_fc.5.2.bn3.weight\", \"resnet_before_fc.5.2.bn3.bias\", \"resnet_before_fc.5.2.bn3.running_mean\", \"resnet_before_fc.5.2.bn3.running_var\", \"resnet_before_fc.5.3.conv1.weight\", \"resnet_before_fc.5.3.bn1.weight\", \"resnet_before_fc.5.3.bn1.bias\", \"resnet_before_fc.5.3.bn1.running_mean\", \"resnet_before_fc.5.3.bn1.running_var\", \"resnet_before_fc.5.3.conv2.weight\", \"resnet_before_fc.5.3.bn2.weight\", \"resnet_before_fc.5.3.bn2.bias\", \"resnet_before_fc.5.3.bn2.running_mean\", \"resnet_before_fc.5.3.bn2.running_var\", \"resnet_before_fc.5.3.conv3.weight\", \"resnet_before_fc.5.3.bn3.weight\", \"resnet_before_fc.5.3.bn3.bias\", \"resnet_before_fc.5.3.bn3.running_mean\", \"resnet_before_fc.5.3.bn3.running_var\", \"resnet_before_fc.6.0.conv3.weight\", \"resnet_before_fc.6.0.bn3.weight\", \"resnet_before_fc.6.0.bn3.bias\", \"resnet_before_fc.6.0.bn3.running_mean\", \"resnet_before_fc.6.0.bn3.running_var\", \"resnet_before_fc.6.1.conv3.weight\", \"resnet_before_fc.6.1.bn3.weight\", \"resnet_before_fc.6.1.bn3.bias\", \"resnet_before_fc.6.1.bn3.running_mean\", \"resnet_before_fc.6.1.bn3.running_var\", \"resnet_before_fc.6.2.conv1.weight\", \"resnet_before_fc.6.2.bn1.weight\", \"resnet_before_fc.6.2.bn1.bias\", \"resnet_before_fc.6.2.bn1.running_mean\", \"resnet_before_fc.6.2.bn1.running_var\", \"resnet_before_fc.6.2.conv2.weight\", \"resnet_before_fc.6.2.bn2.weight\", \"resnet_before_fc.6.2.bn2.bias\", \"resnet_before_fc.6.2.bn2.running_mean\", \"resnet_before_fc.6.2.bn2.running_var\", \"resnet_before_fc.6.2.conv3.weight\", \"resnet_before_fc.6.2.bn3.weight\", \"resnet_before_fc.6.2.bn3.bias\", \"resnet_before_fc.6.2.bn3.running_mean\", \"resnet_before_fc.6.2.bn3.running_var\", \"resnet_before_fc.6.3.conv1.weight\", \"resnet_before_fc.6.3.bn1.weight\", \"resnet_before_fc.6.3.bn1.bias\", \"resnet_before_fc.6.3.bn1.running_mean\", \"resnet_before_fc.6.3.bn1.running_var\", \"resnet_before_fc.6.3.conv2.weight\", \"resnet_before_fc.6.3.bn2.weight\", \"resnet_before_fc.6.3.bn2.bias\", \"resnet_before_fc.6.3.bn2.running_mean\", \"resnet_before_fc.6.3.bn2.running_var\", \"resnet_before_fc.6.3.conv3.weight\", \"resnet_before_fc.6.3.bn3.weight\", \"resnet_before_fc.6.3.bn3.bias\", \"resnet_before_fc.6.3.bn3.running_mean\", \"resnet_before_fc.6.3.bn3.running_var\", \"resnet_before_fc.6.4.conv1.weight\", \"resnet_before_fc.6.4.bn1.weight\", \"resnet_before_fc.6.4.bn1.bias\", \"resnet_before_fc.6.4.bn1.running_mean\", \"resnet_before_fc.6.4.bn1.running_var\", \"resnet_before_fc.6.4.conv2.weight\", \"resnet_before_fc.6.4.bn2.weight\", \"resnet_before_fc.6.4.bn2.bias\", \"resnet_before_fc.6.4.bn2.running_mean\", \"resnet_before_fc.6.4.bn2.running_var\", \"resnet_before_fc.6.4.conv3.weight\", \"resnet_before_fc.6.4.bn3.weight\", \"resnet_before_fc.6.4.bn3.bias\", \"resnet_before_fc.6.4.bn3.running_mean\", \"resnet_before_fc.6.4.bn3.running_var\", \"resnet_before_fc.6.5.conv1.weight\", \"resnet_before_fc.6.5.bn1.weight\", \"resnet_before_fc.6.5.bn1.bias\", \"resnet_before_fc.6.5.bn1.running_mean\", \"resnet_before_fc.6.5.bn1.running_var\", \"resnet_before_fc.6.5.conv2.weight\", \"resnet_before_fc.6.5.bn2.weight\", \"resnet_before_fc.6.5.bn2.bias\", \"resnet_before_fc.6.5.bn2.running_mean\", \"resnet_before_fc.6.5.bn2.running_var\", \"resnet_before_fc.6.5.conv3.weight\", \"resnet_before_fc.6.5.bn3.weight\", \"resnet_before_fc.6.5.bn3.bias\", \"resnet_before_fc.6.5.bn3.running_mean\", \"resnet_before_fc.6.5.bn3.running_var\", \"resnet_before_fc.7.0.conv3.weight\", \"resnet_before_fc.7.0.bn3.weight\", \"resnet_before_fc.7.0.bn3.bias\", \"resnet_before_fc.7.0.bn3.running_mean\", \"resnet_before_fc.7.0.bn3.running_var\", \"resnet_before_fc.7.1.conv3.weight\", \"resnet_before_fc.7.1.bn3.weight\", \"resnet_before_fc.7.1.bn3.bias\", \"resnet_before_fc.7.1.bn3.running_mean\", \"resnet_before_fc.7.1.bn3.running_var\", \"resnet_before_fc.7.2.conv1.weight\", \"resnet_before_fc.7.2.bn1.weight\", \"resnet_before_fc.7.2.bn1.bias\", \"resnet_before_fc.7.2.bn1.running_mean\", \"resnet_before_fc.7.2.bn1.running_var\", \"resnet_before_fc.7.2.conv2.weight\", \"resnet_before_fc.7.2.bn2.weight\", \"resnet_before_fc.7.2.bn2.bias\", \"resnet_before_fc.7.2.bn2.running_mean\", \"resnet_before_fc.7.2.bn2.running_var\", \"resnet_before_fc.7.2.conv3.weight\", \"resnet_before_fc.7.2.bn3.weight\", \"resnet_before_fc.7.2.bn3.bias\", \"resnet_before_fc.7.2.bn3.running_mean\", \"resnet_before_fc.7.2.bn3.running_var\", \"downsampled_model.linear0.weight\", \"downsampled_model.linear0.bias\", \"intermediate_genus_model.linear0.weight\", \"intermediate_genus_model.linear0.bias\", \"genus_fc.linear0.weight\", \"genus_fc.linear0.bias\". \n\tUnexpected key(s) in state_dict: \"module_list.0.fc.weight\", \"module_list.0.fc.bias\", \"module_list.2.weight\", \"module_list.2.bias\", \"module_list.3.weight\", \"module_list.3.bias\", \"module_list.4.0.weight\", \"module_list.4.0.bias\", \"pretrained_model.fc.weight\", \"pretrained_model.fc.bias\", \"downsampled_model.weight\", \"downsampled_model.bias\", \"intermediate_genus_model.weight\", \"intermediate_genus_model.bias\", \"genus_fc.0.weight\", \"genus_fc.0.bias\". \n\tsize mismatch for module_list.0.layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for module_list.0.layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for module_list.0.layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for module_list.0.layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for module_list.0.layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.0.layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.0.layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.0.layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.0.layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for module_list.0.layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for module_list.0.layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for module_list.0.layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.0.layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.0.layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.0.layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.0.layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for module_list.0.layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for module_list.0.layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for module_list.0.layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for module_list.0.layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for module_list.0.layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for module_list.0.layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for module_list.0.layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n\tsize mismatch for module_list.1.4.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for module_list.1.4.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for module_list.1.5.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for module_list.1.5.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for module_list.1.5.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.1.5.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.1.5.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.1.5.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for module_list.1.5.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for module_list.1.6.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for module_list.1.6.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for module_list.1.6.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.1.6.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.1.6.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.1.6.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for module_list.1.6.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for module_list.1.7.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for module_list.1.7.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for module_list.1.7.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for module_list.1.7.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for module_list.1.7.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for module_list.1.7.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for module_list.1.7.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n\tsize mismatch for pretrained_model.layer1.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for pretrained_model.layer1.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for pretrained_model.layer2.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for pretrained_model.layer2.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for pretrained_model.layer2.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for pretrained_model.layer2.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for pretrained_model.layer2.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for pretrained_model.layer2.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for pretrained_model.layer2.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for pretrained_model.layer3.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for pretrained_model.layer3.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for pretrained_model.layer3.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for pretrained_model.layer3.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for pretrained_model.layer3.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for pretrained_model.layer3.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for pretrained_model.layer3.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for pretrained_model.layer4.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for pretrained_model.layer4.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for pretrained_model.layer4.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for pretrained_model.layer4.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for pretrained_model.layer4.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for pretrained_model.layer4.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for pretrained_model.layer4.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1]).\n\tsize mismatch for resnet_before_fc.4.0.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 64, 1, 1]).\n\tsize mismatch for resnet_before_fc.4.1.conv1.weight: copying a param with shape torch.Size([64, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 256, 1, 1]).\n\tsize mismatch for resnet_before_fc.5.0.conv1.weight: copying a param with shape torch.Size([128, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n\tsize mismatch for resnet_before_fc.5.0.downsample.0.weight: copying a param with shape torch.Size([128, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 256, 1, 1]).\n\tsize mismatch for resnet_before_fc.5.0.downsample.1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for resnet_before_fc.5.0.downsample.1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for resnet_before_fc.5.0.downsample.1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for resnet_before_fc.5.0.downsample.1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for resnet_before_fc.5.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 512, 1, 1]).\n\tsize mismatch for resnet_before_fc.6.0.conv1.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n\tsize mismatch for resnet_before_fc.6.0.downsample.0.weight: copying a param with shape torch.Size([256, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 512, 1, 1]).\n\tsize mismatch for resnet_before_fc.6.0.downsample.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for resnet_before_fc.6.0.downsample.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for resnet_before_fc.6.0.downsample.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for resnet_before_fc.6.0.downsample.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for resnet_before_fc.6.1.conv1.weight: copying a param with shape torch.Size([256, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1024, 1, 1]).\n\tsize mismatch for resnet_before_fc.7.0.conv1.weight: copying a param with shape torch.Size([512, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n\tsize mismatch for resnet_before_fc.7.0.downsample.0.weight: copying a param with shape torch.Size([512, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 1024, 1, 1]).\n\tsize mismatch for resnet_before_fc.7.0.downsample.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for resnet_before_fc.7.0.downsample.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for resnet_before_fc.7.0.downsample.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for resnet_before_fc.7.0.downsample.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for resnet_before_fc.7.1.conv1.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1, 1])."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from confusion_matrix_plotter import plot_confusion_matrix2, generate_classification_report\n",
    "import numpy as np\n",
    "import os\n",
    "import progressbar\n",
    "\n",
    "paramsIterator = config_parser.getHyperpSelectedIter()  \n",
    "number_of_experiments = sum(1 for e in paramsIterator)\n",
    "paramsIterator = config_parser.getHyperpSelectedIter()    \n",
    "experiment_index = 0\n",
    "\n",
    "datasetManager = dataLoader.datasetManager(experimentName, showListOfSpecies)\n",
    "with progressbar.ProgressBar(max_value=number_of_experiments) as bar:\n",
    "    for experiment_params in paramsIterator:\n",
    "        bar.update(experiment_index)\n",
    "        experiment_params[\"numOfTrials\"] = experiment_params[\"numOfTrials\"] or 1\n",
    "\n",
    "        print(\"experiment \", experiment_index+1, \"/\", number_of_experiments, \": \", experiment_params)\n",
    "\n",
    "        # load images\n",
    "        datasetManager.updateParams(experiment_params)\n",
    "        dataset = datasetManager.getDataset()\n",
    "        speciesList = dataset.getSpeciesList()\n",
    "        numberOfSpecies = len(speciesList)\n",
    "        numberOfGenus = len(dataset.getGenusList())\n",
    "\n",
    "        for i in range(experiment_params[\"numOfTrials\"]):\n",
    "            trialName = os.path.join(experimentName, getModelName(experiment_params, i))\n",
    "\n",
    "            # Train/Load model\n",
    "            architecture = {\n",
    "                \"species\": numberOfSpecies,\n",
    "                \"genus\" : numberOfGenus\n",
    "            }\n",
    "            model = CNN.create_model(architecture, experiment_params)\n",
    "            train_loader, validation_loader, test_loader = datasetManager.getLoaders()\n",
    "            if os.path.exists(CNN.getModelFile(trialName)):\n",
    "                _, _, epochs, time_elapsed = CNN.loadModel(model, trialName)\n",
    "                print(\"Model {0} loaded!\".format(trialName))\n",
    "            else:\n",
    "                _, _, epochs, time_elapsed = CNN.trainModel(train_loader, validation_loader, experiment_params, model, trialName)\n",
    "\n",
    "            # Update trial outcomes for statistics\n",
    "            predlist, lbllist = CNN.getLoaderPredictions(test_loader, model, experiment_params)\n",
    "            ts.addTrialPredictions(experiment_params, predlist, lbllist, numberOfSpecies)\n",
    "            macro_f1 = f1_score(lbllist.cpu(), predlist.cpu(), average='macro')\n",
    "            macro_f1_genus = np.nan\n",
    "            if experiment_params[\"useHeirarchy\"]:\n",
    "                predlist, lbllist = CNN.getLoaderPredictions(test_loader, model, experiment_params, 'genus')\n",
    "                ts_genus.addTrialPredictions(experiment_params, predlist, lbllist, numberOfGenus)\n",
    "                macro_f1_genus = f1_score(lbllist.cpu(), predlist.cpu(), average='macro')\n",
    "\n",
    "            ts.addTrial(experiment_params,\n",
    "                    {'loss': CNN.getCrossEntropyFromLoader(test_loader, model, experiment_params),\n",
    "                     'accuracy': CNN.getAccuracyFromLoader(test_loader, model, experiment_params),\n",
    "                     'macro_f1_species': macro_f1,\n",
    "                     'macro_f1_genus': macro_f1_genus,\n",
    "                     'time': time_elapsed,\n",
    "                     'epochs': epochs\n",
    "                    }, i)\n",
    "        \n",
    "        experiment_index = experiment_index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.showStatistics()\n",
    "ts.saveStatistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.showStatistics(False)\n",
    "ts.saveStatistics(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsIterator = config_parser.getHyperpSelectedIter() \n",
    "for experiment_params in paramsIterator:\n",
    "    experiment_params[\"numOfTrials\"] = experiment_params[\"numOfTrials\"] or 1\n",
    "    \n",
    "    print(\"experiment: \", experiment_params)\n",
    "    \n",
    "    datasetManager.updateParams(experiment_params)\n",
    "    dataset = datasetManager.getDataset()\n",
    "    speciesList = dataset.getSpeciesList()\n",
    "    ts.printTrialConfusionMatrix(experiment_params, speciesList, True)\n",
    "    ts.printF1table(experiment_params, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsIterator = config_parser.getHyperpSelectedIter() \n",
    "for experiment_params in paramsIterator:\n",
    "    experiment_params[\"numOfTrials\"] = experiment_params[\"numOfTrials\"] or 1\n",
    "    if experiment_params[\"useHeirarchy\"]:\n",
    "        print(\"experiment: \", experiment_params)\n",
    "\n",
    "        datasetManager.updateParams(experiment_params)\n",
    "        dataset = datasetManager.getDataset()\n",
    "    \n",
    "        genusList = dataset.getGenusList()\n",
    "        ts_genus.printTrialConfusionMatrix(experiment_params, genusList, True)\n",
    "        ts_genus.printF1table(experiment_params, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.trialScatter('accuracy', 'epochs', False, 'learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.trialScatter('macro_f1_species', 'time', False, 'learning_rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
